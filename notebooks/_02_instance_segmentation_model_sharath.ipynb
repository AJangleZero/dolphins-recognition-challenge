{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp instance_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance segmentation\n",
    "\n",
    "> Instance segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union, Optional, Dict, Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.hub import download_url_to_file\n",
    "import torchvision\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "# Download TorchVision repo to use some files from\n",
    "# references/detection\n",
    "\n",
    "if not Path(\"vision\").exists():\n",
    "\n",
    "    !git clone https://github.com/pytorch/vision.git\n",
    "\n",
    "    !cp vision/references/detection/utils.py .\n",
    "    !cp vision/references/detection/transforms.py .\n",
    "    !cp vision/references/detection/coco_eval.py .\n",
    "    !cp vision/references/detection/engine.py .\n",
    "    !cp vision/references/detection/coco_utils.py .\n",
    "\n",
    "# imports\n",
    "from engine import train_one_epoch, evaluate\n",
    "import transforms as T\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy       : 1.18.5\n",
      "torch       : 1.7.1\n",
      "torchvision : 0.8.2\n",
      "PIL         : 7.2.0\n"
     ]
    }
   ],
   "source": [
    "for m in [np, torch, torchvision, PIL]:\n",
    "    print(f\"{m.__name__:12}: {m.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36K\r\n",
      "drwxr-xr-x 2 sharath sharath 12K Dec 14 14:13 \u001b[0m\u001b[01;34mJPEGImages\u001b[0m/\r\n",
      "drwxr-xr-x 2 sharath sharath 12K Dec 14 14:13 \u001b[01;34mSegmentationClass\u001b[0m/\r\n",
      "drwxr-xr-x 2 sharath sharath 12K Dec 14 14:13 \u001b[01;34mSegmentationObject\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "dataset_root = Path(\"./data/dolphins_200\")\n",
    "dataset_zip = dataset_root.parent / \"dolphins_200.zip\"\n",
    "dataset_url = \"https://s3.eu-central-1.amazonaws.com/ai-league.cisex.org/2020-2021/dolphins-instance-segmentation/dolphins_200.zip\"\n",
    "\n",
    "dataset_zip.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not dataset_zip.exists():\n",
    "    torch.hub.download_url_to_file(\n",
    "        dataset_url,\n",
    "        dataset_zip,\n",
    "        hash_prefix=None,\n",
    "        progress=True,\n",
    "    )\n",
    "    \n",
    "\n",
    "with ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dataset_root)\n",
    "    \n",
    "!ls -lh {dataset_root}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def _enumerate_colors_for_fname(fname: Path) -> Tuple[int, int, int]:\n",
    "    img = Image.open(fname)\n",
    "    colors = [y for x, y in img.getcolors()]\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def enumerate_colors_for_fnames(fnames: List[Path]) -> List[Tuple[int, int, int]]:\n",
    "    \"\"\"This function is used to pin (0, 0, 0) color to the front of palette\"\"\"\n",
    "    colors = np.array([_enumerate_colors_for_fname(fname) for fname in fnames]).reshape(\n",
    "        -1, 3\n",
    "    )\n",
    "    colors = set([tuple(x) for x in colors.tolist() if tuple(x) != (0, 0, 0)])\n",
    "    colors = [(0, 0, 0)] + list(colors)\n",
    "    return {x: i for i, x in enumerate(colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def _substitute_values(xs: np.array, x, y):\n",
    "    \"\"\"Not sure I understand what this does\"\"\"\n",
    "    ix_x = xs == x\n",
    "    ix_y = xs == y\n",
    "    xs[ix_x] = y\n",
    "    xs[ix_y] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def enumerate_image_for_instances(\n",
    "    im: Image, force_black_to_zero: bool = True, max_colors=16\n",
    ") -> np.array:\n",
    "    pallete_mask = im.convert(\"P\", palette=Image.ADAPTIVE, colors=max_colors)\n",
    "\n",
    "    xs = np.array(pallete_mask)\n",
    "\n",
    "    if force_black_to_zero:\n",
    "        _substitute_values(xs, 0, xs.max())\n",
    "\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def enumerate_image_for_classes(\n",
    "    im: Image,\n",
    "    colors: Dict[Tuple[int], int] = None,\n",
    ") -> np.array:\n",
    "    xs = np.array(im)\n",
    "    xs = [\n",
    "        ((xs == color).all(axis=-1)).astype(int) * code\n",
    "        for color, code in colors.items()\n",
    "    ]\n",
    "    xs_sum = xs[0]\n",
    "    for i in range(1, len(xs)):\n",
    "        xs_sum = xs_sum + xs[i]\n",
    "    return xs_sum.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "class DolphinsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"JPEGImages\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"SegmentationClass\"))))\n",
    "        self.instances = list(\n",
    "            sorted(os.listdir(os.path.join(root, \"SegmentationObject\")))\n",
    "        )\n",
    "\n",
    "        fnames = [\n",
    "            os.path.join(self.root, \"SegmentationClass\", mask) for mask in self.masks\n",
    "        ]\n",
    "        self.class_colors = enumerate_colors_for_fnames(fnames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_path = os.path.join(self.root, \"JPEGImages\", self.imgs[idx])\n",
    "        label_path = os.path.join(self.root, \"SegmentationClass\", self.masks[idx])\n",
    "        mask_path = os.path.join(self.root, \"SegmentationObject\", self.instances[idx])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # note that we haven't converted the mask to RGB,\n",
    "        # because each color corresponds to a different instance\n",
    "        # with 0 being background\n",
    "        mask_img = Image.open(mask_path)\n",
    "\n",
    "        mask = enumerate_image_for_instances(mask_img)\n",
    "\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        label_img = Image.open(label_path)\n",
    "        label_array = enumerate_image_for_classes(label_img, self.class_colors)\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            class_mask = label_array * masks[i]\n",
    "            label, count = np.unique(class_mask, return_counts=True)\n",
    "            assert label.shape[0] <= 2\n",
    "            label = max(label)\n",
    "            labels.append(label)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there WAS multi class\n",
    "        # labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DolphinsDataset(dataset_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def get_instance_segmentation_model(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(\n",
    "        pretrained=True\n",
    "    )  # box_score_thresh=0.5\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask, hidden_layer, num_classes\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyColorJitter:\n",
    "    def __init__(self, brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5):\n",
    "        self.torch_color_jitter = torchvision.transforms.ColorJitter(\n",
    "            brightness=brightness, contrast=contrast, saturation=saturation, hue=hue\n",
    "        )\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        image = self.torch_color_jitter(image)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint: incorporate more transformation classes such as RandomCrop etc. (https://pytorch.org/docs/stable/torchvision/transforms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms.append(\n",
    "            MyColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n",
    "        )\n",
    "        # TODO: add additional transforms: e.g. random crop\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "dataset = DolphinsDataset(dataset_root, get_transform(train=True))\n",
    "dataset_test = DolphinsDataset(dataset_root, get_transform(train=False))\n",
    "\n",
    "val_split = 0.2\n",
    "n_val = max(1, round(val_split * len(dataset)))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-n_val])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-n_val:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn,\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# our dataset has two classes only - background and dolphin\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[10, 35], gamma=0.1\n",
    ")  # StepLR(optimizer, step_size=10, gamma=0.1) #MultiStepLR(optimizer, milestones=[10,20], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/40]  eta: 0:00:46  lr: 0.000133  loss: 2.1840 (2.1840)  loss_classifier: 0.6545 (0.6545)  loss_box_reg: 0.2684 (0.2684)  loss_mask: 1.2175 (1.2175)  loss_objectness: 0.0323 (0.0323)  loss_rpn_box_reg: 0.0112 (0.0112)  time: 1.1626  data: 0.6623  max mem: 4474\n",
      "Epoch: [0]  [10/40]  eta: 0:00:16  lr: 0.001414  loss: 1.3183 (1.4456)  loss_classifier: 0.3435 (0.4040)  loss_box_reg: 0.2955 (0.2960)  loss_mask: 0.5938 (0.6859)  loss_objectness: 0.0144 (0.0363)  loss_rpn_box_reg: 0.0187 (0.0234)  time: 0.5365  data: 0.0662  max mem: 4751\n",
      "Epoch: [0]  [20/40]  eta: 0:00:10  lr: 0.002695  loss: 1.1231 (1.1813)  loss_classifier: 0.2340 (0.2956)  loss_box_reg: 0.2788 (0.2788)  loss_mask: 0.4567 (0.5209)  loss_objectness: 0.0303 (0.0438)  loss_rpn_box_reg: 0.0187 (0.0422)  time: 0.4744  data: 0.0072  max mem: 4751\n",
      "Epoch: [0]  [30/40]  eta: 0:00:04  lr: 0.003975  loss: 0.7580 (1.0346)  loss_classifier: 0.1500 (0.2448)  loss_box_reg: 0.2493 (0.2768)  loss_mask: 0.2966 (0.4401)  loss_objectness: 0.0238 (0.0365)  loss_rpn_box_reg: 0.0204 (0.0365)  time: 0.4793  data: 0.0077  max mem: 5186\n",
      "Epoch: [0]  [39/40]  eta: 0:00:00  lr: 0.005000  loss: 0.6455 (0.9417)  loss_classifier: 0.1030 (0.2100)  loss_box_reg: 0.2384 (0.2626)  loss_mask: 0.2621 (0.4008)  loss_objectness: 0.0130 (0.0343)  loss_rpn_box_reg: 0.0149 (0.0339)  time: 0.4821  data: 0.0079  max mem: 5186\n",
      "Epoch: [0] Total time: 0:00:19 (0.4961 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/10]  eta: 0:00:07  model_time: 0.2954 (0.2954)  evaluator_time: 0.0837 (0.0837)  time: 0.7974  data: 0.4145  max mem: 5186\n",
      "Test:  [ 9/10]  eta: 0:00:00  model_time: 0.2702 (0.2749)  evaluator_time: 0.0709 (0.0750)  time: 0.4022  data: 0.0463  max mem: 5186\n",
      "Test: Total time: 0:00:04 (0.4061 s / it)\n",
      "Averaged stats: model_time: 0.2702 (0.2749)  evaluator_time: 0.0709 (0.0750)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.498\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.409\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.779\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.517\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.561\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
      "Epoch: [1]  [ 0/40]  eta: 0:00:43  lr: 0.005000  loss: 0.4194 (0.4194)  loss_classifier: 0.0594 (0.0594)  loss_box_reg: 0.1896 (0.1896)  loss_mask: 0.1648 (0.1648)  loss_objectness: 0.0015 (0.0015)  loss_rpn_box_reg: 0.0042 (0.0042)  time: 1.0930  data: 0.6100  max mem: 5186\n",
      "Epoch: [1]  [10/40]  eta: 0:00:16  lr: 0.005000  loss: 0.5410 (0.5462)  loss_classifier: 0.0756 (0.0835)  loss_box_reg: 0.1706 (0.1860)  loss_mask: 0.2559 (0.2376)  loss_objectness: 0.0104 (0.0166)  loss_rpn_box_reg: 0.0085 (0.0225)  time: 0.5433  data: 0.0623  max mem: 5186\n",
      "Epoch: [1]  [20/40]  eta: 0:00:10  lr: 0.005000  loss: 0.5457 (0.5493)  loss_classifier: 0.0806 (0.0834)  loss_box_reg: 0.1716 (0.1879)  loss_mask: 0.2532 (0.2431)  loss_objectness: 0.0096 (0.0133)  loss_rpn_box_reg: 0.0169 (0.0215)  time: 0.4895  data: 0.0077  max mem: 5186\n",
      "Epoch: [1]  [30/40]  eta: 0:00:05  lr: 0.005000  loss: 0.4918 (0.5243)  loss_classifier: 0.0814 (0.0837)  loss_box_reg: 0.1716 (0.1783)  loss_mask: 0.2282 (0.2330)  loss_objectness: 0.0078 (0.0114)  loss_rpn_box_reg: 0.0144 (0.0179)  time: 0.4903  data: 0.0077  max mem: 5186\n",
      "Epoch: [1]  [39/40]  eta: 0:00:00  lr: 0.005000  loss: 0.4646 (0.5252)  loss_classifier: 0.0750 (0.0837)  loss_box_reg: 0.1392 (0.1725)  loss_mask: 0.1871 (0.2286)  loss_objectness: 0.0078 (0.0125)  loss_rpn_box_reg: 0.0120 (0.0280)  time: 0.4874  data: 0.0077  max mem: 5186\n",
      "Epoch: [1] Total time: 0:00:20 (0.5050 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/10]  eta: 0:00:07  model_time: 0.2673 (0.2673)  evaluator_time: 0.0561 (0.0561)  time: 0.7350  data: 0.4077  max mem: 5186\n",
      "Test:  [ 9/10]  eta: 0:00:00  model_time: 0.2391 (0.2412)  evaluator_time: 0.0439 (0.0459)  time: 0.3382  data: 0.0464  max mem: 5186\n",
      "Test: Total time: 0:00:03 (0.3426 s / it)\n",
      "Averaged stats: model_time: 0.2391 (0.2412)  evaluator_time: 0.0439 (0.0459)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.821\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.809\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.459\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.552\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.491\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.569\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n",
      "Epoch: [2]  [ 0/40]  eta: 0:00:44  lr: 0.005000  loss: 0.4347 (0.4347)  loss_classifier: 0.0547 (0.0547)  loss_box_reg: 0.1265 (0.1265)  loss_mask: 0.2437 (0.2437)  loss_objectness: 0.0021 (0.0021)  loss_rpn_box_reg: 0.0077 (0.0077)  time: 1.1116  data: 0.6236  max mem: 5186\n",
      "Epoch: [2]  [10/40]  eta: 0:00:16  lr: 0.005000  loss: 0.4132 (0.4370)  loss_classifier: 0.0639 (0.0677)  loss_box_reg: 0.1285 (0.1360)  loss_mask: 0.1841 (0.1791)  loss_objectness: 0.0055 (0.0064)  loss_rpn_box_reg: 0.0082 (0.0479)  time: 0.5451  data: 0.0623  max mem: 5186\n",
      "Epoch: [2]  [20/40]  eta: 0:00:10  lr: 0.005000  loss: 0.4502 (0.4814)  loss_classifier: 0.0737 (0.0737)  loss_box_reg: 0.1503 (0.1476)  loss_mask: 0.2037 (0.2119)  loss_objectness: 0.0072 (0.0138)  loss_rpn_box_reg: 0.0137 (0.0344)  time: 0.4937  data: 0.0071  max mem: 5186\n",
      "Epoch: [2]  [30/40]  eta: 0:00:05  lr: 0.005000  loss: 0.4580 (0.4730)  loss_classifier: 0.0724 (0.0737)  loss_box_reg: 0.1536 (0.1461)  loss_mask: 0.2121 (0.2104)  loss_objectness: 0.0093 (0.0126)  loss_rpn_box_reg: 0.0162 (0.0302)  time: 0.4969  data: 0.0078  max mem: 5186\n",
      "Epoch: [2]  [39/40]  eta: 0:00:00  lr: 0.005000  loss: 0.3919 (0.4504)  loss_classifier: 0.0669 (0.0712)  loss_box_reg: 0.1332 (0.1408)  loss_mask: 0.1821 (0.2007)  loss_objectness: 0.0073 (0.0114)  loss_rpn_box_reg: 0.0109 (0.0263)  time: 0.4970  data: 0.0077  max mem: 5186\n",
      "Epoch: [2] Total time: 0:00:20 (0.5117 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/10]  eta: 0:00:06  model_time: 0.2486 (0.2486)  evaluator_time: 0.0404 (0.0404)  time: 0.6806  data: 0.3877  max mem: 5186\n",
      "Test:  [ 9/10]  eta: 0:00:00  model_time: 0.2164 (0.2205)  evaluator_time: 0.0291 (0.0299)  time: 0.2988  data: 0.0447  max mem: 5186\n",
      "Test: Total time: 0:00:03 (0.3022 s / it)\n",
      "Averaged stats: model_time: 0.2164 (0.2205)  evaluator_time: 0.0291 (0.0299)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.821\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.422\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.584\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.798\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.449\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664\n",
      "Epoch: [3]  [ 0/40]  eta: 0:00:43  lr: 0.005000  loss: 0.2529 (0.2529)  loss_classifier: 0.0484 (0.0484)  loss_box_reg: 0.0734 (0.0734)  loss_mask: 0.1227 (0.1227)  loss_objectness: 0.0033 (0.0033)  loss_rpn_box_reg: 0.0052 (0.0052)  time: 1.0878  data: 0.5978  max mem: 5186\n",
      "Epoch: [3]  [10/40]  eta: 0:00:16  lr: 0.005000  loss: 0.4090 (0.4105)  loss_classifier: 0.0620 (0.0601)  loss_box_reg: 0.1292 (0.1238)  loss_mask: 0.1728 (0.1857)  loss_objectness: 0.0056 (0.0081)  loss_rpn_box_reg: 0.0093 (0.0328)  time: 0.5500  data: 0.0603  max mem: 5186\n",
      "Epoch: [3]  [20/40]  eta: 0:00:10  lr: 0.005000  loss: 0.4170 (0.4126)  loss_classifier: 0.0637 (0.0662)  loss_box_reg: 0.1311 (0.1344)  loss_mask: 0.1819 (0.1805)  loss_objectness: 0.0047 (0.0067)  loss_rpn_box_reg: 0.0095 (0.0248)  time: 0.5031  data: 0.0069  max mem: 5186\n",
      "Epoch: [3]  [30/40]  eta: 0:00:05  lr: 0.005000  loss: 0.3819 (0.4230)  loss_classifier: 0.0685 (0.0682)  loss_box_reg: 0.1320 (0.1396)  loss_mask: 0.1846 (0.1871)  loss_objectness: 0.0034 (0.0065)  loss_rpn_box_reg: 0.0127 (0.0217)  time: 0.5080  data: 0.0074  max mem: 5186\n",
      "Epoch: [3]  [39/40]  eta: 0:00:00  lr: 0.005000  loss: 0.3748 (0.4107)  loss_classifier: 0.0621 (0.0668)  loss_box_reg: 0.1320 (0.1368)  loss_mask: 0.1643 (0.1817)  loss_objectness: 0.0032 (0.0061)  loss_rpn_box_reg: 0.0127 (0.0193)  time: 0.5062  data: 0.0076  max mem: 5186\n",
      "Epoch: [3] Total time: 0:00:20 (0.5200 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/10]  eta: 0:00:07  model_time: 0.2676 (0.2676)  evaluator_time: 0.0498 (0.0498)  time: 0.7229  data: 0.4016  max mem: 5186\n",
      "Test:  [ 9/10]  eta: 0:00:00  model_time: 0.2261 (0.2310)  evaluator_time: 0.0331 (0.0357)  time: 0.3166  data: 0.0457  max mem: 5186\n",
      "Test: Total time: 0:00:03 (0.3202 s / it)\n",
      "Averaged stats: model_time: 0.2261 (0.2310)  evaluator_time: 0.0331 (0.0357)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.861\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.455\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.599\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.855\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.544\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
      "Epoch: [4]  [ 0/40]  eta: 0:00:45  lr: 0.005000  loss: 0.4551 (0.4551)  loss_classifier: 0.0714 (0.0714)  loss_box_reg: 0.1646 (0.1646)  loss_mask: 0.2097 (0.2097)  loss_objectness: 0.0025 (0.0025)  loss_rpn_box_reg: 0.0068 (0.0068)  time: 1.1497  data: 0.6466  max mem: 5186\n",
      "Epoch: [4]  [10/40]  eta: 0:00:16  lr: 0.005000  loss: 0.3273 (0.3181)  loss_classifier: 0.0501 (0.0520)  loss_box_reg: 0.1174 (0.1119)  loss_mask: 0.1429 (0.1429)  loss_objectness: 0.0025 (0.0027)  loss_rpn_box_reg: 0.0088 (0.0087)  time: 0.5604  data: 0.0653  max mem: 5186\n",
      "Epoch: [4]  [20/40]  eta: 0:00:10  lr: 0.005000  loss: 0.3273 (0.3405)  loss_classifier: 0.0501 (0.0562)  loss_box_reg: 0.1174 (0.1221)  loss_mask: 0.1429 (0.1506)  loss_objectness: 0.0018 (0.0022)  loss_rpn_box_reg: 0.0088 (0.0095)  time: 0.5052  data: 0.0073  max mem: 5186\n",
      "Epoch: [4]  [30/40]  eta: 0:00:05  lr: 0.005000  loss: 0.4097 (0.3697)  loss_classifier: 0.0597 (0.0586)  loss_box_reg: 0.1329 (0.1265)  loss_mask: 0.1781 (0.1638)  loss_objectness: 0.0021 (0.0027)  loss_rpn_box_reg: 0.0138 (0.0181)  time: 0.5076  data: 0.0072  max mem: 5186\n",
      "Epoch: [4]  [39/40]  eta: 0:00:00  lr: 0.005000  loss: 0.4097 (0.3853)  loss_classifier: 0.0649 (0.0615)  loss_box_reg: 0.1337 (0.1326)  loss_mask: 0.1831 (0.1705)  loss_objectness: 0.0031 (0.0034)  loss_rpn_box_reg: 0.0129 (0.0172)  time: 0.5086  data: 0.0070  max mem: 5186\n",
      "Epoch: [4] Total time: 0:00:20 (0.5240 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/10]  eta: 0:00:07  model_time: 0.2805 (0.2805)  evaluator_time: 0.0619 (0.0619)  time: 0.7401  data: 0.3939  max mem: 5186\n",
      "Test:  [ 9/10]  eta: 0:00:00  model_time: 0.2287 (0.2342)  evaluator_time: 0.0363 (0.0383)  time: 0.3233  data: 0.0462  max mem: 5186\n",
      "Test: Total time: 0:00:03 (0.3266 s / it)\n",
      "Averaged stats: model_time: 0.2287 (0.2342)  evaluator_time: 0.0363 (0.0383)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.848\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.458\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.576\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.704\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.801\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.485\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.491\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "# let's train it for 50 epochs\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[222.4442, 225.1240, 343.3164, 273.7512],\n",
       "          [344.1282, 244.0352, 466.5335, 279.8188],\n",
       "          [334.6013, 226.7830, 396.2329, 258.0442],\n",
       "          [288.2923, 226.9448, 342.5175, 254.3230],\n",
       "          [390.7780, 243.1464, 426.8419, 259.4730],\n",
       "          [355.5486, 243.7918, 426.3789, 261.8110],\n",
       "          [350.9827, 228.3645, 417.8277, 262.1019],\n",
       "          [297.2738, 229.0661, 376.3158, 256.3553],\n",
       "          [375.0706, 234.6990, 425.1687, 260.2922],\n",
       "          [362.1086, 226.0025, 395.6159, 255.3446],\n",
       "          [314.8678, 233.2699, 425.9194, 265.0935],\n",
       "          [244.8049, 252.0540, 354.5661, 274.0536],\n",
       "          [297.9895, 227.4242, 492.5534, 279.9767],\n",
       "          [338.8068, 243.0577, 424.5018, 272.2073],\n",
       "          [326.0295, 242.8014, 368.2765, 256.0810],\n",
       "          [307.6323, 238.2938, 388.3889, 260.2543],\n",
       "          [382.7429, 243.5956, 435.1300, 271.1403],\n",
       "          [253.9753, 260.2061, 311.5323, 273.3116],\n",
       "          [292.7706, 245.9255, 372.9172, 257.2255],\n",
       "          [295.1801, 230.8920, 327.2788, 255.6788],\n",
       "          [330.7999, 237.9381, 379.2907, 252.6186],\n",
       "          [334.4304, 233.1992, 382.4997, 247.3665],\n",
       "          [277.2648, 227.0289, 363.3238, 266.2608],\n",
       "          [303.0334, 240.8124, 367.9326, 253.8952],\n",
       "          [362.3231, 257.7589, 483.9619, 280.0234],\n",
       "          [231.6376, 224.0073, 294.8650, 266.9613],\n",
       "          [335.9773, 255.1538, 445.7911, 275.1161],\n",
       "          [347.4124, 240.0225, 400.1295, 258.1148],\n",
       "          [327.8517, 229.3915, 369.8746, 265.7930],\n",
       "          [319.7215, 247.1402, 366.8120, 259.7628],\n",
       "          [343.9520, 235.4306, 372.1241, 261.3273],\n",
       "          [243.9980, 227.3955, 337.8993, 258.2599],\n",
       "          [272.4387, 232.7942, 315.4077, 268.9630],\n",
       "          [215.3082, 247.8217, 384.0388, 276.5701],\n",
       "          [297.5608, 246.3691, 352.5720, 274.1107],\n",
       "          [282.1201, 241.2291, 368.7102, 261.4009]], device='cuda:0'),\n",
       "  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       "  'scores': tensor([0.9921, 0.9828, 0.9607, 0.9235, 0.9174, 0.8378, 0.8024, 0.6830, 0.6676,\n",
       "          0.6397, 0.5895, 0.5388, 0.4386, 0.4035, 0.3096, 0.1895, 0.1737, 0.1690,\n",
       "          0.1655, 0.1616, 0.1524, 0.1455, 0.1401, 0.1384, 0.1276, 0.1140, 0.0986,\n",
       "          0.0931, 0.0889, 0.0806, 0.0760, 0.0749, 0.0730, 0.0601, 0.0555, 0.0501],\n",
       "         device='cuda:0'),\n",
       "  'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "# pick one image from the test set\n",
    "img, _ = dataset_test[0]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def _show_pred(dataset_test, n=None):\n",
    "    if n == None:\n",
    "        n = len(dataset_test)\n",
    "\n",
    "    for i in range(n):\n",
    "        img = dataset_test[i][0]\n",
    "        display(\n",
    "            Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy()).resize(\n",
    "                (300, 240)\n",
    "            )\n",
    "        )\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            prediction = model([img.to(device)])\n",
    "        predicted_masks = prediction[0][\"masks\"]\n",
    "        scores = prediction[0][\"scores\"]\n",
    "\n",
    "        for i in range(predicted_masks.shape[0]):\n",
    "            score = scores[i]\n",
    "            if score > 0.9:\n",
    "                print(f\"Mask for score {score:.1%}\")\n",
    "                display(\n",
    "                    Image.fromarray(\n",
    "                        predicted_masks[i, 0].mul(255).byte().cpu().numpy()\n",
    "                    ).resize((300, 240))\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Skipping mask for score {score:.1%}\")\n",
    "\n",
    "\n",
    "_show_pred(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def _save_model_with_timestamp(\n",
    "    model, save_path=\"/work/data/dupini/processed/body_100_resized/\"\n",
    "):\n",
    "    save_date_path = (\n",
    "        save_path + \"model\" + datetime.now().strftime(\"-%Y-%m-%d-%H-%M-%S\") + \".pt\"\n",
    "    )\n",
    "    print(save_date_path)\n",
    "    torch.save(model.state_dict(), save_date_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _save_model_with_timestamp(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo\n",
    "\n",
    "# ----- There are IOU and DICE metrics, but finally using only IOU sice it is the most preferred for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1f5f9366a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0miou_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_segmentation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_gt_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mCompute\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mIOU\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0msegmentation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtypically\u001b[0m \u001b[0mone\u001b[0m \u001b[0mground\u001b[0m \u001b[0mtruth\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbinary_segmentation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0mD\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mregion\u001b[0m \u001b[0mof\u001b[0m \u001b[0minterest\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msegmented\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def iou_metric(binary_segmentation: np.array, binary_gt_label: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Compute the IOU between two binary segmentation (typically one ground truth and a predicted one).\n",
    "    Input:\n",
    "        binary_segmentation: binary 2D numpy array representing the region of interest as segmented by the algorithm\n",
    "        binary_gt_label: binary 2D numpy array representing the region of interest as provided in the database\n",
    "    Output:\n",
    "        IOU: IOU between the segmentation and the ground truth\n",
    "    \"\"\"\n",
    "    \n",
    "    assert binary_segmentation.dtype in [np.int, np.bool]\n",
    "    assert binary_gt_label.dtype in [np.int, np.bool]\n",
    "\n",
    "    # turn all variables to booleans, just in case\n",
    "    binary_segmentation = np.asarray(binary_segmentation, dtype=np.bool)\n",
    "    binary_gt_label = np.asarray(binary_gt_label, dtype=np.bool)\n",
    "\n",
    "    # compute the intersection\n",
    "    intersection = np.logical_and(binary_segmentation, binary_gt_label)\n",
    "    union = np.logical_or(binary_segmentation, binary_gt_label)\n",
    "    \n",
    "    # count the number of True pixels in the binary segmentation\n",
    "    segmentation_pixels = float(np.sum(binary_segmentation.flatten()))\n",
    "    \n",
    "    # same for the ground truth\n",
    "    gt_label_pixels = float(np.sum(binary_gt_label.flatten()))\n",
    "    \n",
    "    # same for the intersection and union\n",
    "    intersection = float(np.sum(intersection.flatten()))\n",
    "    union = float(np.sum(union.flatten()))\n",
    "    \n",
    "    # compute the Dice coefficient\n",
    "    smooth = 0.001\n",
    "    IOU = (intersection + smooth)/ (union + smooth)\n",
    "\n",
    "    return IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(binary_segmentation, binary_gt_label):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient between two binary segmentation.\n",
    "    Dice coefficient is defined as here: https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "    Input:\n",
    "        binary_segmentation: binary 2D numpy array representing the region of interest as segmented by the algorithm\n",
    "        binary_gt_label: binary 2D numpy array representing the region of interest as provided in the database\n",
    "    Output:\n",
    "        dice_value: Dice coefficient between the segmentation and the ground truth\n",
    "    \"\"\"\n",
    "\n",
    "    # turn all variables to booleans, just in case\n",
    "    binary_segmentation = np.asarray(binary_segmentation, dtype=np.bool)\n",
    "    binary_gt_label = np.asarray(binary_gt_label, dtype=np.bool)\n",
    "\n",
    "    # compute the intersection\n",
    "    intersection = np.logical_and(binary_segmentation, binary_gt_label)\n",
    "\n",
    "    # count the number of True pixels in the binary segmentation\n",
    "    segmentation_pixels = float(np.sum(binary_segmentation.flatten()))\n",
    "    # same for the ground truth\n",
    "    gt_label_pixels = float(np.sum(binary_gt_label.flatten()))\n",
    "    # same for the intersection\n",
    "    intersection = float(np.sum(intersection.flatten()))\n",
    "\n",
    "    # compute the Dice coefficient\n",
    "    dice_value = 2 * intersection / (segmentation_pixels + gt_label_pixels)\n",
    "\n",
    "    # return it\n",
    "    return dice_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission of results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_metric_array(input_array):\n",
    "    '''\n",
    "    Input:\n",
    "        input_array: input array size m x n containing iou metric values\n",
    "    Output:\n",
    "        cleaned input array\n",
    "    description: \n",
    "        This function makes sure that there is only one max value across the columns\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    max_val = np.argmax(input_array,axis=1)\n",
    "    uniq, uniq_idx, unq_counts = np.unique(max_val, axis=0, return_index=True, return_counts=True)\n",
    "\n",
    "    new_arr = uniq[unq_counts > 1]\n",
    "    if len(uniq)!=max_val.shape[0]:\n",
    "        for row_idx in new_arr:\n",
    "            max_col = np.where(max_val==row_idx)\n",
    "            if input_array[max_col[0][0],row_idx]>=input_array[max_col[0][1],row_idx]:\n",
    "                input_array[max_col[0][1],row_idx] = -1\n",
    "            else:\n",
    "                input_array[max_col[0][0],row_idx] = -1\n",
    "    return input_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inference_test(dataset_test, n=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "        dataset: the dataset for which you need to calculate the metric for\n",
    "        # todo: model also as input?\n",
    "    Output:\n",
    "        mean_dataset_iou: mean IOU metric for entire input dataset\n",
    "    '''\n",
    "    if n == None:\n",
    "        n = len(dataset_test)\n",
    "    test_set_iou = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # get the input image\n",
    "        img = dataset_test[i][0]\n",
    "        \n",
    "        # get the ground-truth mask and convert to numpy\n",
    "        gt_masks_all = dataset_test[i][1][\"masks\"].mul(255).byte().cpu().numpy()\n",
    "        \n",
    "        # evaluate the model on the input image\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            prediction = model([img.to(device)])\n",
    "            \n",
    "        # get the instance mask predictions    \n",
    "        predicted_masks = prediction[0][\"masks\"]\n",
    "        \n",
    "        # get the score \n",
    "        scores = prediction[0][\"scores\"]\n",
    "        \n",
    "        # convert the predicted masks to numpy\n",
    "        pred_masks_all = predicted_masks.squeeze(1).mul(255).byte().cpu().numpy()\n",
    "        \n",
    "        # create an array for the metric with size m x n, \n",
    "        # with m as #instances in the predictions and n as #instance in ground-truth\n",
    "        # ideally m and n should be equal i.e both predicted and ground-truth should contain the same number of instances\n",
    "        \n",
    "        m = pred_masks_all.shape[0]\n",
    "        n = gt_masks_all.shape[0]\n",
    "        \n",
    "        # initialize the array with zeros\n",
    "        iou_array = np.zeros((n, n))  # NOTE: ? change the array size to (m,n) ?\n",
    "\n",
    "        for j in range(n):         # NOTE: ?change to m?\n",
    "            score = scores[j]\n",
    "            if score > 0.9: \n",
    "                pred_mask = pred_masks_all[j, :, :]\n",
    "                for k in range(n):\n",
    "                    gt_mask = gt_masks_all[k, :, :]\n",
    "                    iou_score = iou_metric(pred_mask>127, gt_mask>127) \n",
    "                    iou_array[j,k]=iou_score\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # clean the array to have only one maximum per column\n",
    "        iou_array = clean_metric_array(clean_metric_array(clean_metric_array(iou_array)))\n",
    "\n",
    "        # mean iou metric for all the instance for a single input image\n",
    "        single_test_iou = np.mean(np.max(iou_array, axis=1))\n",
    "        test_set_iou.append(single_test_iou)\n",
    "        \n",
    "    # mean iou metric for the entire dataset\n",
    "    mean_dataset_iou = np.mean(np.array(test_set_iou))\n",
    "    return mean_dataset_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6507149984288729\n"
     ]
    }
   ],
   "source": [
    "mean_test_iou = inference_test(dataset_test)                             \n",
    "print(mean_test_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
